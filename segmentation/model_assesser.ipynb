{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment Notebook\n",
    "\n",
    "Used on the inter-intra notebook, to get fair assessment between notebooks as train/validate/splits may be different between users due to different approaches and unset random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import load_img\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH_ORIGINAL=512\n",
    "IMG_HEIGHT_ORIGINAL=1024\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1 # grayscale images\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "NUM_CLASSES = 8 #8 in case just fluids is 4, in case fluids and layers is 8\n",
    "BATCH_SIZE = 4 # try 4, 8, 12, 16, 32\n",
    "\n",
    "SRF_CLASS = 6\n",
    "IRF_CLASS = 7\n",
    "\n",
    "CLASS_LABELS = (\n",
    "    \"Above ILM\",\n",
    "    \"ILM-IPL/INL\",\n",
    "    \"IPL/INL-RPE\",\n",
    "    \"RPE-BM\",\n",
    "    \"Under BM\",\n",
    "    \"PED\",\n",
    "    \"SRF\",\n",
    "    \"IRF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AROISequenceNoTransform(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_train_paths = input_img_paths\n",
    "        self.target_train_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.target_train_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_train_paths = self.input_train_paths[i : i + self.batch_size]\n",
    "        batch_target_train_paths = self.target_train_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((BATCH_SIZE,) + self.img_size + (1,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_train_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            img=np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "            x[j] = img/.255\n",
    "        y = np.zeros((BATCH_SIZE,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_train_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            img = np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "            y[j] = img\n",
    "        return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./oct_model_20230125-092315\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTER_INTRA_DATA = Path(\"../data/AROI_labelled_scans/inter_intra/\")\n",
    "inter_intra_mask_path = sorted([file for file in INTER_INTRA_DATA.glob(\"**/number/*png\")])\n",
    "inter_intra_raw_path = sorted([file for file in INTER_INTRA_DATA.glob(\"**/raw/*png\")])\n",
    "\n",
    "inter_intra_seq = AROISequenceNoTransform(BATCH_SIZE, IMG_SIZE, inter_intra_raw_path, inter_intra_mask_path)\n",
    "\n",
    "inter_predictions = model.predict(inter_intra_seq)\n",
    "print(inter_predictions.shape)\n",
    "inter_predictions = np.argmax(inter_predictions, axis=-1)\n",
    "\n",
    "inter_masks = utils.get_masks_from_keras_sequence(inter_intra_seq)\n",
    "\n",
    "cf_matrix = confusion_matrix(inter_masks.flatten(), inter_predictions.flatten())\n",
    "cf_matrix_normal = cf_matrix.astype('float32') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "utils.make_confusion_matrix(cf_matrix_normal, count = False, percent = False, figsize=(7,7), cbar=True, cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{' InterIntra Report ':=^55}\")\n",
    "print(classification_report(inter_masks.flatten(), inter_predictions.flatten(), target_names=CLASS_LABELS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "77487d1edd2e6510460e5d28cf7c827c95b8721bd96e2faadbb986014f6405ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
