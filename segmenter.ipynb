{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop and Segment\n",
    "\n",
    "Using a pre-trained model, crop into our image and produce segmented images for classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH_ORIGINAL=512\n",
    "IMG_HEIGHT_ORIGINAL=1024\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNELS = 1 # grayscale images\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "NUM_CLASSES = 8 #8 in case just fluids is 4, in case fluids and layers is 8\n",
    "BATCH_SIZE = 4 # try 4, 8, 12, 16, 32\n",
    "\n",
    "SRF_CLASS = 6\n",
    "IRF_CLASS = 7\n",
    "\n",
    "CLASS_LABELS = (\n",
    "    \"Above ILM\",\n",
    "    \"ILM-IPL/INL\",\n",
    "    \"IPL/INL-RPE\",\n",
    "    \"RPE-BM\",\n",
    "    \"Under BM\",\n",
    "    \"PED\",\n",
    "    \"SRF\",\n",
    "    \"IRF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./oct_model_20230125-092315\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTID_DATA = Path(\"./data/OCTID/\")\n",
    "\n",
    "normal = OCTID_DATA.glob(\"**/NORMAL*\")\n",
    "armd = OCTID_DATA.glob(\"**/AMRD*.jpeg\")\n",
    "dr = OCTID_DATA.glob(\"**/DR*\")\n",
    "mh = OCTID_DATA.glob(\"**/MH*\")\n",
    "csr = OCTID_DATA.glob(\"**/CSR1*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_img_paths = [*normal]\n",
    "armd_img_paths = [*armd]\n",
    "dr_img_paths = [*dr]\n",
    "mh_img_paths = [*mh]\n",
    "csr_img_paths = [*csr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCTIDSequence(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_train_paths = input_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.input_train_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_train_paths = self.input_train_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((BATCH_SIZE,) + self.img_size + (1,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_train_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            # Crop into image!\n",
    "            img = img[:, 142:-142]\n",
    "            img=np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "            x[j] = img/.255\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77487d1edd2e6510460e5d28cf7c827c95b8721bd96e2faadbb986014f6405ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
